{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb1df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openai import OpenAI\n",
    "from io import BytesIO, StringIO\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "embedding_engine = 'text-embedding-ada-002'\n",
    "OPENAI_API_KEY = \"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\"#os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "366657b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=15, max=60), stop=stop_after_attempt(10))\n",
    "def embedding_with_backoff(**kwargs):\n",
    "    return client.embeddings.create(**kwargs)\n",
    "\n",
    "def get_openai_embedding(text, model=embedding_engine):\n",
    "    result = embedding_with_backoff(\n",
    "        model=model,\n",
    "        input=[text]\n",
    "    )\n",
    "    return result.data[0].embedding\n",
    "\n",
    "def compute_doc_embeddings_openai(df: pd.DataFrame):\n",
    "    return {idx: get_openai_embedding(r.content) for idx, r in df.iterrows()}\n",
    "\n",
    "#Future function to generate the embeddings from an S3 file\n",
    "def get_text_from_md_file(s3, bucket, key):\n",
    "    s3Object = s3.get_object(Bucket=bucket, Key=key)\n",
    "    file_buffer = BytesIO(s3Object['Body'].read())\n",
    "    \n",
    "    decoded_content = unidecode.unidecode(content)\n",
    "\n",
    "    return decoded_content\n",
    "\n",
    "def get_document_embeddings(text):\n",
    "    chunk_size = 1500\n",
    "    chunk_overlap = 150\n",
    "\n",
    "    r_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\" \\n---\\n  \",\"\\n\\n\", \"\\n\", \"(?<=\\-.)\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    splits = r_splitter.split_text(text)\n",
    "\n",
    "    df_text = pd.DataFrame(splits, columns=['content'])\n",
    "\n",
    "    openai_embeddings = pd.DataFrame(compute_doc_embeddings_openai(df_text))\n",
    "    \n",
    "    return df_text, openai_embeddings\n",
    "    \n",
    "#Future function to upload the embeddings to S3\n",
    "def upload_documents(raw_text, pages, df_text, df_embeddings, s3, bucket, key):\n",
    "    csv_buffer = StringIO()\n",
    "    csv_vector_buffer = StringIO()\n",
    "    \n",
    "    document_name_array = os.path.splitext(key)\n",
    "    \n",
    "    # Upload both .txt files\n",
    "    txt_document_name = document_name_array[0] + '.txt'\n",
    "    s3.put_object(Body=raw_text,Bucket=bucket,Key=txt_document_name)\n",
    "\n",
    "    # Upload file with the text for embeddings\n",
    "    df_text.to_csv(csv_buffer, index=False)\n",
    "    csv_filename = document_name_array[0] + '_embeddings_text.csv'\n",
    "    s3.put_object(Body=csv_buffer.getvalue(), Bucket=S3_BUCKET, Key=csv_filename)\n",
    "\n",
    "    # Upload file with the embeddings\n",
    "    df_embeddings.to_csv(csv_vector_buffer, index=False)\n",
    "    csv_embeddings_filename = document_name_array[0] + '_embeddings.csv'\n",
    "    s3.put_object(Body=csv_vector_buffer.getvalue(), Bucket=S3_BUCKET, Key=csv_embeddings_filename)\n",
    "\n",
    "    n_of_pages = len(pages)\n",
    "\n",
    "    return txt_document_name, n_of_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b50f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pattern = 'sagemaker_documentation/*.md'\n",
    "\n",
    "markdown_texts = []\n",
    "\n",
    "for file_path in glob.glob(path_pattern):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        decoded_content = unidecode.unidecode(content)\n",
    "\n",
    "        markdown_texts.append(decoded_content)\n",
    "        \n",
    "text = \" \\n---\\n  \".join(markdown_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9480d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6417f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt, df_embddng = get_document_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4451d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt.to_csv('df_text.csv', index=False)\n",
    "df_embddng.to_csv('df_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
