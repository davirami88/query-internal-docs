{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef94db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openai import OpenAI\n",
    "from io import BytesIO, StringIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "embedding_engine = \"text-embedding-ada-002\"\n",
    "GPT3_turbo = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "OPENAI_API_KEY = \"OPENAI_API_KEY\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get embeddings files from local drive\n",
    "with open('text.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "df_txt = pd.read_csv('files/embeddings/df_text.csvdf_text.csv')\n",
    "df_embddng = pd.read_csv('files/embeddings/df_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9bf0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=15, max=60), stop=stop_after_attempt(10))\n",
    "def embedding_with_backoff(**kwargs):\n",
    "    return client.embeddings.create(**kwargs)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=15, max=60), stop=stop_after_attempt(10))\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs, timeout=30)\n",
    "\n",
    "def get_openai_embedding(text, model=embedding_engine):\n",
    "    result = embedding_with_backoff(\n",
    "        model=model,\n",
    "        input=[text]\n",
    "    )\n",
    "    return result.data[0].embedding\n",
    "\n",
    "def vector_similarity(x, y):\n",
    "    return cosine_similarity(np.array(x).reshape(1, -1), np.array(y).reshape(1, -1))[0][0]\n",
    "\n",
    "def compute_doc_embeddings_openai(df: pd.DataFrame):\n",
    "    return {idx: get_openai_embedding(r.content) for idx, r in df.iterrows()}\n",
    "\n",
    "def order_document_sections_by_query_similarity_openai(query, contexts):\n",
    "    query_embedding = get_openai_embedding(query)\n",
    "    document_similarities = sorted([(vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()], reverse=True)\n",
    "    return document_similarities\n",
    "\n",
    "def get_openai_response(prompt, text, model):\n",
    "    response = chat_completion_with_backoff(model=model,\n",
    "                                            response_format={ \"type\": \"json_object\" },\n",
    "                                            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "                                                      {\"role\": \"user\", \"content\": text + prompt}],\n",
    "                                            temperature=0)\n",
    "    try:\n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        result = []\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_query_response(query):\n",
    "    text_ranking = order_document_sections_by_query_similarity_openai(query, df_embeddings)[:25]\n",
    "\n",
    "    separator = \"\\n\\n------\\n\\n\"  # Clear visual separator\n",
    "    prompt_check_query = \"\"\"Based on the text provided, you are to determine if it is possible to answer this question: \"\"\" + query + \"\"\"\n",
    "    Please answer \"yes\" only if the answer to the question is in the text explicitly, clearly and unambiguously, and if the text contains the specific information to answer the question.\n",
    "    If is not possible to answer based on the text or does not directly and clearly identify the answer, or if there is any ambiguity or assumption required to identify them, you must answer \"no\".\n",
    "    Return your answer on the key \"answer\".\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"Based on the text, which is a selected part of a whole documentation, return a JSON with a single answer in the key \"answer\". \n",
    "    You must not recommend read the docs, beacause the text is an specific part of the whole documentation. \n",
    "    Try to be as generic as possible and always based your answer on the text provided. Question: \"\"\" + query \n",
    "\n",
    "    valid_text_options = []\n",
    "\n",
    "    for option in text_ranking:\n",
    "        text_index = int(re.findall(r'\\d+', str(option[1]))[0])\n",
    "        possible_text = text[text.find(df_text.loc[text_index, \"content\"][:30]) - 500:text.find(df_text.loc[text_index, \"content\"][:30]) + 2500]\n",
    "\n",
    "        response = get_openai_response(prompt_check_query, possible_text + separator, GPT3_turbo)\n",
    "\n",
    "        if response['answer'] == 'yes':\n",
    "            valid_text_options.append(possible_text)\n",
    "\n",
    "    if len(valid_text_options) > 0:\n",
    "        valid_text = \" \".join(valid_text_options)\n",
    "\n",
    "        response_user_query = get_openai_response(prompt, valid_text + separator, GPT3_turbo)\n",
    "\n",
    "        return response_user_query['answer']\n",
    "    else:\n",
    "        return \"openai_error\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa8dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f85a28e",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4703d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models. It offers first-party templates for organizations to quickly get started with ML workflows and CI/CD, using AWS-native services such as AWS CodeBuild, AWS CodePipeline, and AWS CodeCommit. SageMaker Projects help organizations set up and standardize developer environments for data scientists and CI/CD systems for MLOps engineers, providing dependency management, code repository management, build reproducibility, and artifact sharing.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = \"What is SageMaker?\"\n",
    "\n",
    "get_query_response(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52fc152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regions': ['us-east-1',\n",
       "  'us-east-2',\n",
       "  'us-west-2',\n",
       "  'eu-west-1',\n",
       "  'ap-northeast-1',\n",
       "  'ap-northeast-2',\n",
       "  'ap-southeast-2',\n",
       "  'eu-central-1']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2 = \"What are all AWS regions where SageMaker is available?\"\n",
    "\n",
    "get_query_response(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8564f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To check if an endpoint is KMS encrypted, you can look at the 'EndpointConfigWithDataCapture' resource in the CloudFormation template. If the 'KmsKeyId' property is specified within the 'DataCaptureConfig' section, then the endpoint is KMS encrypted.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = \"How to check if an endpoint is KMS encrypted?\"\n",
    "\n",
    "get_query_response(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "976d59a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SageMaker geospatial capabilities are a set of managed services that perform operations on behalf of the user on AWS hardware managed by SageMaker. These capabilities can only perform operations that the user permits and require an IAM execution role to grant the service permission to access AWS resources.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_4 = \"What are SageMaker Geospatial capabilities?\"\n",
    "\n",
    "get_query_response(test_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
